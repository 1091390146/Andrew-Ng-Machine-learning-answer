# Andrew-Ng Machinelearning answer
  ex1、目前只添加了第六节线性回归的答案，单变量和多变量完整答案，后续会继续添加  
  ex2、添加了逻辑回归完整答案，本章重在理解，从推导sigmoid函数到极大似然估计法推导公式，再求导，运用梯度上升或者*(-1/m)运用梯度下降；
正则化需要注意是用来限制theta的，而theta(1)也就是对应X为1的那一列不需要正则化，因为会限制theta(1)上升或者下降，无法达到最值点；  
  ex3、完成了第三次多元分类与神经网络作业，注意理解多元分类运用的逻辑回归，本质也是一个0 1 分类问题，只不过把相对应的单元划为1，其余划为0去训练;  
oneVsAll.m文件里面有对本次作业图片识别的对应说明，注意附加的神经网络作业已经给出了Theta抛砖引玉，只需理解即可;


